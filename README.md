# master degree project: a forensic grographic corrdinate prediction pipeline
#### course: degree project
#### credit: 45
#### student: Yuexin Yu
#### Supervisor: Eran Elhaik

This is the README file containing the workflow to construct this forensic geopragic cooridnate prediction pipeline.

The required input are available in *Data* directory.

All required packages in R are listed in packages.R

> Introduction. 

  This is an admixture-based pipeline to predict smaplesâ€˜ geographic coordinates in given test set. The pipeline applies the following general workflow:  
  * 1. Extract an AIM set from both training set and test set
  * 2. Calculate portions of pupative ancestral populations of traing set and test set repsectively, by ADMIXTURE in supervised mode.
  * 3. Predict the geographic coordinates for samples in test set based on the model trained by Random Forest using training set.   

> Load packages in R 4.1.2
``` r

```

  
> 0. Functions
```r
rf_latlong <- function(training, testing, variables, coast=NULL, nthread=8){
  # Model training by random forest method and use the model to predict test set. Then adjust predicted geographic coordinates based on world point data and coastline data
  # @training: the data frame of training set, having sample names, corresponding ancestral population portion calculation, GRC, origin latitude and longitude, as well as country.
  # @test: the data frame of test set, having sample names, corresponding ancestral population portion calculation, GRC, origin latitude and longitude, as well as country.
  # @variables: a list of column names used in model training
  # @coast: If coast = NULL, which is the feault, it means no need data adjustment after prediction; otherwise, it should be the coastline data generated in rf_model_training function. 
  # @nthread: number of threads to use when running this function. The default is 8.
  
  set.seed(1234)
  
  # create 5 subsets in training for cross validation
  folds <- createFolds(training[,'Populations'], k = 5, returnTrain = T)
  
  # ask cross validation when model training; the model training will be a regression
  trControl <-  trainControl( # regression
    method = "cv",
    number = 5,
    verboseIter = FALSE,
    returnData = FALSE,
    search = "grid",
    savePredictions = "final",
    allowParallel = T,
    index = folds)
  
  # use a range of value as the value of parameter so that all value will be tested and the model with smallest RMSE will be finally used
  tune_grid <- expand.grid(.mtry = c(1:15))
  
  # train for latitude
  training$rowIndex <- as.numeric(rownames(training))
  Xgb_latitude <- train(x = training[,variables],
                        y = training[,'latitude'],
                        method = "rf",
                        trControl = trControl,
                        tuneGrid = tune_grid ,
                        nthread = nthread
  )
  
  # train for longitude
  Xgb_longitude <- train(x = training[,variables],
                         y = training[,'longitude'],
                         method = "rf",
                         trControl = trControl,
                         tuneGrid = tune_grid ,
                         nthread = nthread
  )
  
  # predict the test set
  latPred <- predict(Xgb_latitude, newdata = testing[,variables])
  longPred <- predict(Xgb_longitude, newdata = testing[,variables])
  
  #adjust out of bounds predictions
  message('adjust out of bounds predictions')
  longPred[longPred > 180] <- 180
  longPred[longPred < -180] <- -180
  latPred[latPred > 90] <- 90
  latPred[latPred < -90] <- -90
  #Pull to nearest coastline if provided
  message('Pull to nearest coastline if provided')
  find_coast <- function(long, lat) { # find the closet point on the coast for the given long and lat
    distances_from_coastline <- sp::spDistsN1(coast, c(long, lat), longlat = TRUE)
    
    closest_point <-  which.min(distances_from_coastline)
    new_coords <- coast[closest_point,]
    
    return(new_coords)
    
  }
  
  if (!is.null(coast)) {
    message('toAdjust generated by function map.where')
    # find the longPred / latPred that are not on world latitude/longitude
    toAdjust <-
      which(is.na(maps::map.where(database = "world", longPred, latPred)))
    
    if(length(toAdjust) > 0){
      # apply find_coast function to adjust the latitude and longitude of given toAdjust index
      message('adjusted generated by mapply find_coast and longPred, latPred')
      adjusted <- mapply(find_coast, long = longPred[toAdjust], lat = latPred[toAdjust])
      
      # update the adjusted lat and long
      longPred[toAdjust] <- adjusted[1,]
      latPred[toAdjust] <- adjusted[2,]
    }
  }
  
  mean_r2 <- mean(c(Xgb_longitude$results$Rsquared[which(Xgb_longitude$results$mtry == Xgb_longitude$bestTune[[1]])],
                    Xgb_latitude$results$Rsquared[which(Xgb_latitude$results$mtry == Xgb_latitude$bestTune[[1]])]
  ))
  
  message('return')
  return(list(list(latPred, longPred),
              mean_r2) )
  
  
}


rf_model_training <- function(qfile_nogp_popFilter, tag, extraColumn=''){
  
  # @qfile_nogp_popFilter: the data frame with sample names, corresponding ancestral population portion calculations, sample's latitude and longitude, GRC, as well as country
  # @tag: a string which is the suffix added in the file path 
  # @extraColumn: a string. If run model training in random forest method, extraColumn = '', which is the default. If run model training in random forest with an extra column added, extraColumn = <the extra column name>
  
  # prepare coastline data for the adjustment of predicted geographic coordinate
  coastlines <- cbind("x"  = maps::SpatialLines2map(rworldmap::coastsCoarse)$x ,"y" =maps::SpatialLines2map(rworldmap::coastsCoarse)$y)
  coastlines <- coastlines[complete.cases(coastlines),]
  coastlines <- coastlines[coastlines[,1] < 180 ,]
  
  GeoPreds <- list()
  
  # extract the ancestral population names
  gp <- colnames(qfile_nogp_popFilter)[-c(1,2,12,13,14)]
  
  # add the name of extra column if needed
  if(extraColumn != ''){
    gp <- c(gp, extraColumn)
    
  }
  
  set.seed(18)
  
  # split qfile_nogp_popFilter into 5 subsets.
  trainFolds <-  caret::createFolds(qfile_nogp_popFilter$Populations, k = 5, returnTrain = T)
  
  GeoPreds <- list()
  
  # For each iteration, use 4 subsets as training set, the left one as test set to do model training and prediction. Since there are 5 subsets, iteration is 5 so that all samples are finally tested
  start_time <- Sys.time()
  for (i in 1:5){
    
    train <- qfile_nogp_popFilter[trainFolds[[i]],]
    test <- qfile_nogp_popFilter[-trainFolds[[i]],]
    
    start_time.adm <- Sys.time()
    testPreds <-rf_latlong(training = train, testing = test,
                           variables = gp, coast=coastlines)
    GeoPreds[[i]] <- testPreds
    
    end_time.adm <- Sys.time()
    time_for_testPreds <- end_time.adm - start_time.adm
    # message(time_for_testPreds)
    
    
  }
  end_time <- Sys.time()
  time_for_testPreds_ind <- end_time - start_time
  message(time_for_testPreds_ind) # 
  
  # Add predicted geographic coordinates to corresponding samples
  add_preds <- list()
  for (i in 1:5){
    
    add_preds[[i]] <- cbind(qfile_nogp_popFilter[-trainFolds[[i]],] ,
                            "latPred" = GeoPreds[[i]][[1]],
                            "longPred" = GeoPreds[[i]][[2]] )
    
  }
  
  # Add predicted geographic coordinates to corresponding samples
  MetasubDataPreds <- plyr::rbind.fill(add_preds)
  
  # Save the data frame as a csv file
  if(extraColumn == ''){
    write.csv(MetasubDataPreds,paste0("qfile_predict_rf_",tag,".csv"))
    
  }else{
    write.csv(MetasubDataPreds,paste0("qfile_predict_extraCol_",tag,".csv"))
    
  }
  
  # MetasubDataPreds <- read.csv(paste0("qfile_predict_rf_",tag,".csv"))
  
  # Calculate the distance between the original and the predicted geographic coordinates, added to column 'Distance_from_origin'
  for (i in 1:nrow(MetasubDataPreds)){
    MetasubDataPreds[i,"Distance_from_origin"] <- geosphere::distm(c(MetasubDataPreds[i,"longPred"],MetasubDataPreds[i,"latPred"]), c(MetasubDataPreds[i,"longitude"],MetasubDataPreds[i,"latitude"]), fun = geosphere::distHaversine)/1000
  }
  
  # Print distance from origin results 
  print(c(mean(MetasubDataPreds$Distance_from_origin ),
          median(MetasubDataPreds$Distance_from_origin ),
          median(MetasubDataPreds$Distance_from_origin[which(MetasubDataPreds$Distance_from_origin < 100)])))
  
  if(!file.exists('../median_distance_from_the_origin')){
    system("touch median_distance_from_the_origin")
  }
  system(paste0("echo '",ii,",",median(MetasubDataPreds$Distance_from_origin ),"'  >> median_distance_from_the_origin"))

}


maf_tbl_generation <- function(marker_frq, marker_ped,
                               rdata_output_path){
  # Return a table having sample in row, SNP in column. Each cell is the minor allele frequency of the SNP in current column for the sample in current row.
  
  # @marker_frq: The data frame read from .frq file
  # @marker_ped: The data frame read from .ped file
  # @rdata_output_path: A strin gof file path to save the MAF data frame in rdata
  
  marker_frq <- marker_frq[-1,]
  minor_allele.df <- data.frame(SNP = marker_frq$V2, MA = marker_frq$V3)
  
  marker_ped.allele <-  marker_ped[,c(1,7:ncol(marker_ped))] # row: individual column: genotype (biallelic)
  
  print('Start MAF')
  
  # Minor allele frequencies calculation
  start_time <- Sys.time()
  pop <- unique(marker_ped.allele$V1)
  if(length(pop) > 1){
    marker_freq <- data.frame(population = pop) # note that iteration of marker_ped.allele$V1 = marker_freq$individual
    for(i in 1:nrow(minor_allele.df)){ # i is index of marker
      if(i %% 10000 == 0){ # easy to track
        message(paste('Currently in i=', i))
      }
      freqs <- c()
      minor_allele <- minor_allele.df[i,2]
      for(j in pop){ #j is individual
        pop_ave <- mean(stringr::str_count(marker_ped.allele[which(marker_ped.allele$V1 %in% j),1+i],
                                           pattern = as.character(minor_allele))
                        * 0.5 ) # get the average of minor allele frequency of one population for current marker
        freqs <- c(freqs, pop_ave)
      }
      marker_freq <- cbind(marker_freq, freqs) # bind the minor allele frequencies for all individual in this marker to the result data frame
    }
  }else{# length(pop) = 1
    marker_freq <- data.frame(population = marker_ped.allele$V1) # note that iteration of marker_ped.allele$V1 = marker_freq$individual
    for(i in 1:nrow(minor_allele.df)){ # i is index of marker
      if(i %% 10000 == 0){ # easy to track
        message(paste('Currently in i=', i))
      }
      freqs <- c()
      minor_allele <- minor_allele.df[i,2]
      for(j in 1:nrow(marker_ped.allele)){ #j is individual
        # print(paste('j: ', j))
        pop_ave <- mean(stringr::str_count(marker_ped.allele[j,1+i],
                                           pattern = as.character(minor_allele))
                        * 0.5 ) # get the average of minor allele frequency of one population for current marker
        freqs <- c(freqs, pop_ave)
        
      }
      marker_freq <- cbind(marker_freq, freqs) # bind the minor allele frequencies for current individual in this marker to the result data frame
      
    }
  }
  
  colnames(marker_freq) <- c('Populations', minor_allele.df$SNP) # SNP name as column name
  
  end_time <- Sys.time()
  time_for_marker_freq <- end_time - start_time
  print(time_for_marker_freq)
  
  # Save MAF table
  metasub_data<- marker_freq
  save(metasub_data, file = rdata_output_path)
  return(metasub_data)
}


add_meta_ref <- function(metasub_data, meta){
  # Return metasub_data with corresponding country, latitude, longitude added for all samples
  # This function is only used for output_645 set

  # @metasub_data: A data frame having population and GRC information for all samples from output_645 set
  # @meta: A data frame having meta data for output_645 set
  
  # Remove meta data not having enough information
  meta_latlong <- meta[which(sapply(X = meta$inCountry, FUN = isTRUE)),]
  
  # Remove samples having population name that not in the meta data
  metasub_data <- metasub_data[which(metasub_data$Populations %in% meta_latlong$nameArgument),]
  meta_latlong$country <- make.names(meta_latlong$country)
  
  # Add country, latitude, longitude to the corresponding population
  metasub_data$country <- NA
  metasub_data$latitude <- NA
  metasub_data$longitude <- NA
  for(i in 1:nrow(metasub_data)){
    the_population <- metasub_data$Populations[i]
    metasub_data$country[i] <- meta_latlong$country[which(meta_latlong$nameArgument == the_population)]
    metasub_data$latitude[i] <- meta_latlong$latitidue[which(meta_latlong$nameArgument == the_population)]
    metasub_data$longitude[i] <- meta_latlong$longitude[which(meta_latlong$nameArgument == the_population)]
  }
  
  return(metasub_data)
}


add_meta_reich <- function(qfile_nogp, meta){
  # Return qfile_nogp with meta data (country, latitude, longitude) added, and population is also changed to corresponding version ID in AADR set
  # This function is only used for AADR set
  
  # @qfile_nogp: A data frame having population and GRC information for all samples from AADR set
  # @meta: A data frame having meta data for AADR set
  
  # filter out meta data not in given data frame, and the samples from the given data frame that not in meta data
  meta_pop <- meta[which(meta$Version.ID %in% qfile_nogp$GRC),]
  message(nrow(meta_pop))
  qfile_nogp_popFilter <- qfile_nogp[which(qfile_nogp$GRC %in% meta_pop$Version.ID),]
  message(nrow(qfile_nogp_popFilter)) # the number of rows in the given data frame and meta data should be the same after filtration
  
  meta_pop$Country <- make.names(meta_pop$Country)
  meta_pop$Version.ID <- as.character(meta_pop$Version.ID)
  
  # Add country, latitude, longitude to the corresponding population
  qfile_nogp_popFilter$country <- NA
  qfile_nogp_popFilter$latitude <- NA
  qfile_nogp_popFilter$longitude <- NA
  for(i in 1:nrow(qfile_nogp_popFilter)){
    versionID <- qfile_nogp_popFilter$GRC[i]
    qfile_nogp_popFilter$Populations[i] <- as.character(meta_pop$Group_Label[which(meta_pop$Version.ID == versionID)])
    qfile_nogp_popFilter$country[i] <- as.character(meta_pop$Country[which(meta_pop$Version.ID == versionID)])
    qfile_nogp_popFilter$latitude[i] <- as.numeric(as.character(meta_pop$Lat.[which(meta_pop$Version.ID == versionID)]))
    qfile_nogp_popFilter$longitude[i] <- as.numeric(as.character(meta_pop$Long.[which(meta_pop$Version.ID == versionID)]))
  }
  
  return(qfile_nogp_popFilter)
}


null_importance_select <-function(x, features, seed=123, shuffle=F,cores = 16) {
  # Return a feature importance table for all feature by fit model to latitude and longitude respectively, and sum the feature importance of both latitude and longitude as one feature's feature importance.
  
  # @x: A data frame containing columns used for model training, and the target to fit
  # @features: A list of feature names in x, which is used in model training
  # @shuffle: A boolean. If FALSE, the targets map to corresponding sample, which is the default; otherwise, the targets will be randomly shift to other samples
  # @cores: An integer. The number of cores to run this function
  
  
  y.lat <- x$latitude
  y.long <-x$longitude
  
  # Shuffle target if required
  if(isTRUE(shuffle)){
    
    new_order_x <- x[sample(nrow(x), size = nrow(x)),]
    y.lat <- new_order_x$latitude
    y.long <- new_order_x$longitude
  }
  
  dtrain.lat <- lgb.Dataset(data = as.matrix(x[,-c(ncol(x)-1,ncol(x))]), label = y.lat, free_raw_data=F)
  
  lgb_params <- list(objective = "regression",
                     boosting = 'rf',
                     subsample = 0.623,
                     colsample_bytree = 0.7,
                     num_leaves = 137,
                     max_depth = 8,
                     seed = seed,
                     bagging_freq = 1,
                     n_jobs = cores)
  
  # fit the model for latitude
  clf.lat <- lgb.train(params=lgb_params, data=dtrain.lat, nrounds=200, init_model=NULL)
  
  
  
  dtrain.long <- lgb.Dataset(data = as.matrix(x[,-c(ncol(x)-1,ncol(x))]), label = y.long, free_raw_data=F)
  
  # fit the model for longitude
  clf.long <- lgb.train(params=lgb_params, data=dtrain.long, nrounds=200)
  
  # Get feature importances, sum the feature importance in latitude and longitude as a feature's feature importance
  ftr_importance.long <- lgb.importance(clf.long, percentage = F)[,c('Feature','Gain', 'Frequency')]
  ftr_importance.lat <- lgb.importance(clf.lat, percentage = F)[,c('Feature','Gain', 'Frequency')]
  for(i in 1:nrow(ftr_importance.long)){
    current_fea <- ftr_importance.long$Feature[i]
    if(current_fea %in% ftr_importance.lat$Feature){ # lat + long
      ftr_importance.lat$Gain[which(ftr_importance.lat$Feature == current_fea)] <- sum(c(ftr_importance.lat$Gain[which(ftr_importance.lat$Feature == current_fea)], ftr_importance.long$Gain[i]))
      ftr_importance.lat$Frequency[which(ftr_importance.lat$Feature == current_fea)] <- sum(c(ftr_importance.lat$Frequency[which(ftr_importance.lat$Feature == current_fea)], ftr_importance.long$Frequency[i]))
    }else{
      ftr_importance.lat <- rbind(ftr_importance.lat, ftr_importance.long[i,])
    }
  }
  imp_df <- ftr_importance.lat
  colnames(imp_df) <- c('feature', 'importance_gain', 'importance_split')
  
  return(imp_df)
}


rf_model_training_train_test <- function(qfile_train_nogp_popFilter, qfile_test_nogp_popFilter, tag){
  # A pipeline to 
  # 1. run model training by random forest and prediction
  # 2. save predicted latitude and longitude, as well as mean R2 for trained model 
  
  # @qfile_train_nogp_popFilter: The data frame of training set, having sample names, corresponding ancestral population portion calculations, sample's latitude and longitude, GRC, as well as country 
  # @qfile_test_nogp_popFilter: The data frame of test set, having sample names, corresponding ancestral population portion calculations, sample's latitude and longitude, GRC, as well as country 
  # @tag: a list, 
  #       element 1: ind i.e. test_name
  #       element 2: ite i.e. selected_feature_set (baseline/bench/split300)
  
  if(ncol(qfile_train_nogp_popFilter) != ncol(qfile_test_nogp_popFilter)){
    stop(paste('num of columns in train and test is not equal for case', tag[[1]]))
  }
  
  # prepare coastline data for the adjustment of predicted geographic coordinate
  coastlines <- cbind("x"  = maps::SpatialLines2map(rworldmap::coastsCoarse)$x ,"y" =maps::SpatialLines2map(rworldmap::coastsCoarse)$y)
  coastlines <- coastlines[complete.cases(coastlines),]
  coastlines <- coastlines[coastlines[,1] < 180 ,]
  
  # extract columns used for model training
  gp <- colnames(qfile_train_nogp_popFilter)[-c(1,2,12,13,14)]
  
  # random forest model training and prediction
  start_time <- Sys.time()
  run_rlt <-rf_latlong(training = qfile_train_nogp_popFilter, 
                                  testing = qfile_test_nogp_popFilter,
                                  variables = gp, coast=coastlines)
  testPreds <- run_rlt[[1]]
  r2 <- run_rlt[[2]]
  
  end_time <- Sys.time()
  time_for_testPreds <- end_time- start_time
  message(time_for_testPreds)
  
  # write mean R2 value into a file
  system(paste0("echo '",tag[[1]],"_",tag[[2]],",",r2,"' >> mean_R2"))
  
  # add predicted results to the test set data frame
  add_preds <- cbind(qfile_test_nogp_popFilter,
                     "latPred" = testPreds[[1]],
                     "longPred" = testPreds[[2]] )
  
  # save test set data frame
  save(add_preds, file = paste0(tag[[1]],'_',tag[[2]],'_qfile.rdata'))
  MetasubDataPreds <- paste(add_preds, collapse = ',')
  
  system(paste0("echo '",MetasubDataPreds,"' >> ", tag[[2]], "_rf_rlt"))
  
}






```
> 1. AADR set data preparation
  Codes here are perfomed in Bash command. [PLINK 1.9](https://www.cog-genomics.org/plink/1.9/) is required. Since some of file sizes here are over the size limit on github, only the result files with the prefix *reich_here_overlap* are provided in the main directory.
  ```console
  # Get overlaps between ancestrial population set and AADR set
  plink --bfile ../Genographic/num_Admixture_reference_pops --extract reich_here.bim --make-bed --out genepool_overlap_SNP --noweb
  
  # keep only overlapped SNPs in AADR set
  plink --bfile reich_here --extract ../Genographic/num_Admixture_reference_pops.bim --make-bed --out reich_here_overlap --noweb
  ```
  
> 2. AIM set curation using AADR set 

Note: Only the final result files (in 2..) is provided in *Data* directory

* 2.1. Randomly split AADR samples into 2 based on a filtration criteria, do 100 times

The filtration criteria:  

Before data splitting, countires having sample size < 5 should be discarded.  

During splitting, split smaples in each country into 2 sets in same size. If the sample size after splitting < 5, all samples in this country are put into training set. Otherwise, training set and test set will get random samples from this country in same size.   

Codes here are performed in R 4.1.2. 

```r
  # load meta
  meta <- read.csv('Data/meta_table') #nrow(meta)=14008
  # load sample tbl
  fam <- read.table('Data/reich_here_overlap.fam')[,2] 
  fam_file <- read.table('Data/reich_here_overlap.fam')
  meta <- meta[which(meta$Version.ID %in% fam),] 

  # remove countries having samples < 5
  ctry_count <- as.data.frame(table(meta$Country))
  smaller_than_five <- ctry_count$Var1[which(ctry_count$Freq<=5)]
  meta <- meta[-which(meta$Country %in% smaller_than_five ),] 
  ctry_count <- ctry_count[-which(ctry_count$Freq<=5),] 


  for(j in 1:100){
  sample_set1 <- c()
  sample_set2 <- c()
  
  # select half of samples from each country
   for(i in 1:nrow(ctry_count)){
     ctry <- ctry_count$Var1[i]
     ctry_sample <- meta$Version.ID[which(meta$Country == ctry)]
     split_size <- ceiling(length(ctry_sample)/2)
     if(split_size >= 5){ # if sample size after splitting < 5, all samples in this country are put into training set
       sample_set1 <- c(sample_set1, sample(ctry_sample, size = split_size))
       sample_set2 <- c(sample_set2, ctry_sample[-which(ctry_sample %in% sample_set1)])
     }else{ # if not, put into 2 sets
       sample_set1 <- c(sample_set1, ctry_sample)
     }
   }
   if(length(sample_set1) + length(sample_set2) == nrow(meta)){ # ensure no sample missing
     reference_sample <- fam_file[which(fam_file$V2 %in% sample_set1),]
     test_sample <- fam_file[which(fam_file$V2 %in% sample_set2),]
      
     # save them into file, ans save to a corresponding directory
     dir.create(paste0('dt',j))
     write.table(reference_sample, file = paste0('dt',j,'/reference_sample'),
                  quote = F, row.names = F, sep = '\t')
     write.table(test_sample, file = paste0('dt',j,'/test_sample'),
                  quote = F, row.names = F, sep = '\t')
   }else{
     message(nrow(reference_sample))
     message(nrow(test_sample))
     stop(paste0('In iteration ',j,', the sum of reference sample size and test sample size is not equal to the size of Reich dataset'))
   }
  
  
  }

```

* 2.2. For each set of split AADR training and test sets:
  
All R code in section 2.2. can be in one R file *ref_pipeline.R*, and run with arugument passing through this script in Bash command such as:

(Note that *<num>* represents *the number of current set from 100 runs*)

```console
  Rscript --vanilla ref_pipeline.R <num>
```
  
In ref_pipeline.R, start with:
```r
  args <- commandArgs(trailingOnly=TRUE)
  ii <- args[1]
  setwd(paste0('dt',ii))
```
  
to navigate to the directory having split sample sets in the number of current set from 100 runs.

  + 2.2.1. Extract samples for training set and test set
  
  Codes here are performed in R. PLINK 1.9 is required. 
  ```r
     system('plink --bfile ../reich_here_overlap --keep reference_sample --make-bed --out reference_reich --noweb')
     system('plink --bfile ../reich_here_overlap --keep test_sample --make-bed --out test_reich --noweb')

  ```
  + 2.2.2. Prepare training set + run ADMIXTURE in supervised mode for training set
  
  Codes here are performed in R. Both [PLINK 1.07](https://zzz.bwh.harvard.edu/plink/download.shtml) and PLINK 1.9 are required.
  ```r
    system('sh ../baseline_preparation')
  ```
  
  where *baseline_preparation*:
  
  (Note that ADMIXTURE is required, and is prepared in main page named as *admixture32*)
  ```console
    # since the coding of base is different for AADR set and ancestral population set, convert the base in AADR set
    ~/bin/plink-1.07-x86_64/plink --bfile reference_reich --allele1234 --make-bed --out reference_reich_qc --noweb

    # try to merge training set with ancestral population set, will get an error due to different allelic location in 2 sets, will automatically generate a .missno file
    plink --bfile reference_reich_qc --bmerge ../genepool_overlap.bed ../genepool_overlap.bim ../genepool_overlap.fam  --make-bed --out baseline_overlap --noweb --allow-no-sex

    # remove SNPs in different alleleic location
    plink --bfile ../genepool_overlap --exclude genepool_overlap_missnp --make-bed --out genepool_overlap_qc
    plink --bfile reference_reich_qc --exclude reference_reich_qc_missnp --make-bed --out reich_here_qc2
    
    # merge genepool to AADR set
    plink --bfile reich_here_qc2 --bmerge genepool_overlap_qc.bed genepool_overlap_qc.bim genepool_overlap_qc.fam  --make-bed --out baseline_overlap --noweb --allow-no-sex
  
    ### To avoid error in ADMIXTURE due to some of samples having all SNPs missing, do quality control for the set
    # Calculate missing rate 
    plink --bfile baseline_overlap --missing --out baseline_overlap --noweb

    # Get the number of SNPs in baseline_overlap
    wc -l baseline_overlap.bim # to get the number of SNPs in baseline_overlap

    # Get samples having all SNPs missing
    cat baseline_overlap.imiss  | awk '{if($4==109627) print $2}' >  baseline_overlap_missing_all_SNPs 

    # Remove collected samples
    cat baseline_overlap.fam | grep -wEf baseline_overlap_missing_all_SNPs > baseline_overlap_removeIndividual.txt  
    plink --bfile baseline_overlap --remove baseline_overlap_removeIndividual.txt --noweb --allow-no-sex --make-bed --out baseline_overlap_qc
  
    # Generate population  file for ADMIXTURE in supervised mode
    cut -f1-2 -d ' ' baseline_overlap_qc.fam > baseline_overlap_qc.pop.txt
    printf '%.0s\n' {1..1756}  > baseline_overlap_qc.pop
    cat baseline_overlap_qc.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> baseline_overlap_qc.pop

    # Run ADMIXTURE in supervised mode
    ../admixture32 baseline_overlap_qc.bed -F 9 -j8

    # Add header to Q file generated from ADMIXTURE
    cat baseline_overlap_qc.fam | cut -d ' ' -f1-2 > training_out_ind_id
    sed -i 's/ /\t/g' training_out_ind_id
    sed -i 's/ /\t/g' baseline_overlap.9.Q
    paste training_out_ind_id baseline_overlap.9.Q > out_Q_training_baseline_<num>
    sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_training_baseline  
  ```
  
  + 2.2.3. Model training for training set with non-curated SNPs (baseline)
    
  Baseline is used as a reference to see the performance of model with selected AIMs
  ```r
    qfile <- read.table('out_Q_training_baseline', header = T, sep = '\t')

    # Add meta information
    meta <- read.csv('../meta_table') 
  
    qfile_nogp <- qfile[-which(qfile$Population %in% c('NorthEastAsian', 'Mediterranean',
                                                   'SouthAfrican', 'SouthWestAsian',
                                                   'NativeAmerican', 'Oceanian',
                                                   'SouthEastAsian', 'NorthernEuropean',
                                                   'SubsaharanAfrican')), ] 
    qfile_nogp$Populations<- as.character(qfile_nogp$Populations)
    qfile_nogp_popFilter <- add_meta_reich(qfile_nogp, meta)
    qfile_nogp_popFilter <- droplevels(qfile_nogp_popFilter)
    str(qfile_nogp_popFilter)
    save(qfile_nogp_popFilter, file = 'baseline_qfile.rdata')

    qfile_nogp_popFilter$GRC <- as.character(qfile_nogp_popFilter$GRC)
    if(sum(is.na(qfile_nogp_popFilter$longitude)) > 0){ # avoid the case that any longitude value from meat_table is invalid
      qfile_nogp_popFilter <- qfile_nogp_popFilter[-which(is.na(qfile_nogp_popFilter$longitude)),]
    }
    
    # Model training
    rf_model_training(qfile_nogp_popFilter,tag = ind)
  ```

  + 2.2.4. Make minor allele frequency (MAF) table for each sample 
                              
  Prepare frequency file and PED file for MAF table construction
  ```r
    system("plink --bfile baseline_overlap_qc --recode --tab --out CONVERTReference")
    system("plink --bfile baseline_overlap_qc --freq --noweb")
    system("mv plink.frq reference.frq")

    # If the disk size is highly limited, these files can be removed
    # system('rm baseline_overlap.*')
    # system('rm genepool_overlap*')
    # system('rm reference_reich*')
    # system('rm reich_here*')
    # system('rm CONVERTReference.map')
    # system('rm CONVERTReference.log')
    # system('rm CONVERTReference.nosex')

  ```
                              
  Construct MAF table
  ```r
    # extracted markers from reference
    marker_frq <- read.table('reference.frq')
    marker_ped <- read.table('CONVERTReference.ped', sep = '\t')
    
    metasub_data <- maf_tbl_generation(marker_frq, marker_ped,
                                       'MAF_reference.rdata')
    system('rm CONVERTReference.ped')

  ```
  
  Add meta data to MAF table 
  ```r
  load('MAF_reference.rdata')
  reference_fam <- read.table('reference_sample', sep='\t')[-1,]
  metasub_data <- metasub_data[-which(metasub_data$Populations %in% c('NorthEastAsian', 'Mediterranean',
                                                                      'SouthAfrican', 'SouthWestAsian',
                                                                      'NativeAmerican', 'Oceanian',
                                                                      'SouthEastAsian', 'NorthernEuropean',
                                                                      'SubsaharanAfrican')), ]
  
  print(paste0('nrow of metasub_data after removing gene pools: ',nrow(metasub_data)))
  
  metasub_data$GRC <- NA
  for(i in 1:nrow(metasub_data)){
    metasub_data$GRC[i] <- as.character(reference_fam$V2[which(reference_fam$V1 == metasub_data$Populations[i])])
  }
  print('metasub_data:')
  str(metasub_data)
  
  # Add meta information
  meta <- read.csv('../meta_table') 
  metasub_data_meta <- add_meta_reich(metasub_data, meta)
  
  if(sum(is.na(metasub_data_meta$longitude)) > 0){
    str(metasub_data_meta)
    stop(paste0('Number of NA longitude: ',sum(is.na(metasub_data_meta$longitude))))
  }else{
    metasub_data_meta$latitude <- as.numeric(metasub_data_meta$latitude)
    metasub_data_meta$longitude <- as.numeric(metasub_data_meta$longitude)
    
    print('metasub_data_meta:')
    str(metasub_data_meta)
    
    save(metasub_data_meta, file='metasub_data_maf_ref.rdata')
    system('rm MAF_reference.rdata')
  }

  ```
  
  feature selection with null importance
  ```r
  ##### Data preparation #####
  load('metasub_data_maf_ref.rdata')

  trial_dt <- metasub_data_meta
  trial_dt <- trial_dt[,c(2:(ncol(trial_dt)-4),
                          grep('latitude', colnames(trial_dt)),
                          grep('longitude', colnames(trial_dt)))] # only remains MAF columns, latitude column, and longitude column 

  x <- trial_dt
  features <- colnames(trial_dt)[c(1:(ncol(trial_dt)-2))]
  if(length(features) + 5 != ncol(metasub_data_meta)){ # 5 columns : Populations, GRC, country, latitude, longitude
    stop('Number of length +5 not equal to MAF table') # if the equation does not meet, more/less features were extracted
  }
  
  
  ##### benchmarking generation #####
  benchmark <- null_importance_select(x=x, features= features,
                                      shuffle=F, seed=123)
  print('benchmark:')
  head(benchmark)
  
  save(benchmark, file = 'benchmark.rdata')
  write.table(benchmark$feature, file = 'benchmark.snp', quote = F, row.names = F, col.names = F)
  
  ##### null importance #####
  null_imp_df <- data.frame()
  nb_runs <- 80 # shuffle 80 times
  start_time <- Sys.time()
  dsp <- c() 
  for(i in 1:nb_runs){
    # Get current run importances
    imp_df <- null_importance_select(x=x, features= features,
                                     shuffle=T, seed=123)
    imp_df$run <- i
    # Concat the latest importances with the old ones
    if(nrow(null_imp_df)==0){
      null_imp_df <- imp_df
    }else{
      null_imp_df<- rbind(null_imp_df, imp_df)
    }
    # Display current run and time used
    spent = Sys.time() - start_time
    dsp <- c(dsp,paste0('Done with    ', i,' of ',nb_runs, '    (spent ', spent,')' )) 
    print(dsp)
    
  }
  end_time <- Sys.time()
  time_for_testPreds_ind <- end_time - start_time
  print(time_for_testPreds_ind)
  
  print('null_imp_df:')
  head(null_imp_df)
  
  save(null_imp_df, file = 'null_imp_df.rdata')

  ##### sync features in null importance and benchmark #####
  load('null_imp_df.rdata')
  load('benchmark.rdata')
  null_imp_df.cp <- null_imp_df
  benchmark.cp <- benchmark
  null_imp_fea <- unique(null_imp_df.cp$feature)
  
  # if features in benchmark does not present in features in data frame having 80 shuffle feature importance results, add this benchmark feature.
  for(j in 1:nrow(benchmark.cp)){ 
    current_fea_benchmark <- benchmark.cp$feature[j]
    if(!current_fea_benchmark %in% null_imp_df$feature){
      null_imp_df <- rbind(as.data.frame(null_imp_df),
                           c(current_fea_benchmark, 0, 0, 0))
    }
  }
  if(sum(!benchmark.cp$feature %in% null_imp_fea) + length(null_imp_fea) != length(unique(null_imp_df$feature))){
    print(paste0('num of features in benchmark not in null_imp + num of features in null_imp: ',sum(!benchmark.cp$feature %in% null_imp_fea) + length(null_imp_fea)))
    print(paste0('num of features in null_imp after adding', length(unique(null_imp_df$feature))))
    stop('check the equivalence between benchmark$feature and null_imp$feature')
    
  }else{
    # if features in data frame having 80 shuffle feature importance results does not present in features in benchmark, add this feature
    for(i in 1:length(null_imp_fea)){
      current_fea <- null_imp_fea[i]
      if(!current_fea %in% benchmark$feature){
        benchmark <- rbind(as.data.frame(benchmark), c(current_fea, 0, 0))
      }
    }
    
    if(  nrow(benchmark) == length(unique(null_imp_df$feature)) ){
      benchmark$importance_gain <- as.numeric(benchmark$importance_gain)
      benchmark$importance_split <- as.numeric(benchmark$importance_split)
      null_imp_df$importance_gain <- as.numeric(null_imp_df$importance_gain)
      null_imp_df$importance_split <- as.numeric(null_imp_df$importance_split)
      null_imp_df$run <- as.numeric(null_imp_df$run)
      
      save(benchmark, file = 'benchmark_full.rdata')
      save(null_imp_df, file = 'null_imp_df_full.rdata')
      
    }else{
      print('num of features in benchmark: ', nrow(benchmark))
      print('num of features in null_imp: ', length(unique(null_imp_df$feature)))
      stop('num of row in benchmark does not equal to features in null_imp_df')
    }
    
  }
  
  
    ##### calculate the feature scoring for each feature in benchmark #####
  load('benchmark_full.rdata')
  load('null_imp_df_full.rdata')
  
  feature_scores <- data.frame(feature=NA, split_score=NA, gain_score=NA)
  for (f in unique(benchmark$feature)){
    f_null_imps_gain <- null_imp_df$importance_gain[null_imp_df$feature == f]
    f_act_imps_gain <- mean(benchmark$importance_gain[benchmark$feature == f])
    gain_score <- log(1e-10 + f_act_imps_gain / (1 + quantile(f_null_imps_gain, c(.75))[[1]]))  # Avoid divide by zero
    f_null_imps_split <- null_imp_df$importance_split[null_imp_df$feature == f]
    f_act_imps_split <- mean(benchmark$importance_split[benchmark$feature == f])
    split_score <- log(1e-10 + f_act_imps_split / (1 +  quantile(f_null_imps_split, c(.75))[[1]]))  # Avoid divide by zero
    feature_scores<- rbind(feature_scores,
                           c(f, split_score, gain_score))
    
  }
  
  scores_df <- feature_scores[-1,]
  scores_df$split_score <- as.numeric(scores_df$split_score)
  scores_df$gain_score <- as.numeric(scores_df$gain_score)
  
  print('75 percentile scores_df:')
  str(scores_df)
  
  save(scores_df, file = 'scores_df_75.rdata')
  
  #### select the features in top 300 feature score ####
    filter_selected_fea <- scores_df$feature[which(scores_df$gain_score>0 & scores_df$split_score>0)]

    filter_selected_fea.order <- filter_selected_fea[order(filter_selected_fea, decreasing = T),]
    write.table(filter_selected_fea.order[c(1:300)], file = 'split300.snp', quote = F, row.names = F, col.names = F)

  ```
                                 
  + 2.2.5. Extract selected SNPs in training set + Run ADMIXTURE in supervised mode for training set after feature selection
  
  ```r
    load('metasub_data_maf_ref.rdata')

    system("plink --bfile baseline_overlap_qc --extract split300.snp --make-bed --out selected_fea_score")
    # Generate population  file for ADMIXTURE in supervised mode
    system("cut -f1-2 -d ' ' selected_fea_score.fam > selected_fea_score.pop.txt")
    system(paste0("printf '%.0s\n' {1..",nrow(metasub_data_meta),"}  > selected_fea_score.pop")) #if any sample was filtered out previously when running add_meta_reich function in 2.2.4 section, the number here no longer holds. It should always be the number of lines in selected_fea_score.fam 

    system("sh ../aft_fea_sel_command")
    system("rm selected_fea_score*")

  ```
                 
  where *aft_fea_sel_command*:
  ```bash session
     cat selected_fea_score.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> selected_fea_score.pop

      # Run ADMIXTURE in supervised mode
      ~/admixture32 selected_fea_score.bed -F 9 -j8

      # Add header to Q file generated from ADMIXTURE
      cat selected_fea_score.fam | cut -d ' ' -f1-2 > out_ind_id_selected_fea_score
      sed -i 's/ /\t/g' out_ind_id_selected_fea_score
      sed -i 's/ /\t/g' selected_fea_score.9.Q
      paste out_ind_id_selected_fea_score selected_fea_score.9.Q > out_Q_values_ref_selected_fea_score_$2
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African' out_Q_values_ref_split300
  ```
  
  + 2.2.6. Model training by random forest and prediction for training set
  ```r
    qfile <- read.table('out_Q_values_ref_split300', header = T, sep = '\t')

    # Add meta information
    meta <- read.csv('../meta_table') 

    qfile_nogp <- qfile[-which(qfile$Population %in% c('NorthEastAsian', 'Mediterranean',
                                                   'SouthAfrican', 'SouthWestAsian',
                                                   'NativeAmerican', 'Oceanian',
                                                   'SouthEastAsian', 'NorthernEuropean',
                                                   'SubsaharanAfrican')), ] 
    qfile_nogp$Populations<- as.character(qfile_nogp$Populations)
    qfile_nogp_popFilter <- add_meta_reich(qfile_nogp, meta)
    qfile_nogp_popFilter <- droplevels(qfile_nogp_popFilter)
    str(qfile_nogp_popFilter)
    save(qfile_nogp_popFilter, file =  'out_Q_values_ref_split300.rdata')

    qfile_nogp_popFilter$GRC <- as.character(qfile_nogp_popFilter$GRC)
    if(sum(is.na(qfile_nogp_popFilter$longitude)) > 0){ # avoid the case that any longitude value from meat_table is invalid
      qfile_nogp_popFilter <- qfile_nogp_popFilter[-which(is.na(qfile_nogp_popFilter$longitude)),]
    }

    rf_model_training(qfile_nogp_popFilter,tag = 'split300')

  ```
                     
* 2.3. Set the selected SNPs from the split set having the smallest distance from the origin in training set

```r
    setwd('~/')
    distance_in_100runs <- read.csv('median_distance_from_the_origin', header = F)
    distance_in_100runs <- distance_in_100runs[order(distance_in_100runs$V2, decreasing = F),]# order based on the median distance from the origin from the smallest to the highest 
    the_best_set <- distance_in_100runs[1,] # the set finally be selected. Its selected SNP set will be the AIM set finally use
    print(the_best_set)
  
    # get the average value of median distance from the origin for 100 runs
    mean(distance_in_100runs[,2])

                   
```
* 2.4. Compare model training methods for the best split set

  
  
* 2.5. AIM selection for the test set in the best split set
  
  In this step, most of codes are same to other sections in 2.. However, only the test set in the best split set is used, and no baseline modeling needed.
  
  All following codes in R can be put into *test_pipeline.R*:
  
  (Note that *<best_num>* represents *the number from 100 runs for the best split set*)
  ```r
    setwd(paste0('dt', <best_num>) # <best_num> = the_best_set[,1])
    
    system('sh test_preparation')
  ```
  
  where *test_preparation*:
  ```console
    # since the coding of base is different for AADR set and ancestral population set, convert the base in AADR set
    ~/bin/plink-1.07-x86_64/plink --bfile test_reich --allele1234 --make-bed --out test_reich_qc --noweb

    # try to merge training set with ancestral population set, will get an error due to different allelic location in 2 sets, will automatically generate a .missno file
    plink --bfile test_reich_qc --bmerge ../../genepool_overlap.bed ../../genepool_overlap.bim ../../genepool_overlap.fam  --make-bed --out test_overlap --noweb --allow-no-sex

    # remove SNPs in different alleleic location
    plink --bfile ../../genepool_overlap --exclude genepool_overlap_missnp --make-bed --out genepool_overlap_qcplink --bfile test_reich_qc --exclude test_reich_qc_missnp --make-bed --out reich_here_qc2

    ### To avoid error in ADMIXTURE due to some of samples having all SNPs missing, do quality control for the set
    # Calculate missing rate 
    plink --bfile test_overlap --missing --out test_overlap --noweb

    # Get the number of SNPs in test_overlap
    wc -l test_overlap.bim # to get the number of SNPs in test_overlap

    # Get samples having all SNPs missing
    cat test_overlap.imiss  | awk '{if($4==109627) print $2}' >  test_overlap_missing_all_SNPs 

    # Remove collected samples
    cat test_overlap.fam | grep -wEf test_overlap_missing_all_SNPs > test_overlap_removeIndividual.txt  
    plink --bfile test_overlap --remove test_overlap_removeIndividual.txt --noweb --allow-no-sex --make-bed --out test_overlap_qc
  ```
  
  ```r
    ########## make frequency file and PED file for test set  ##########
    
    system("plink --bfile test_overlap_qc --recode --tab --out CONVERTTest")
    system("plink --bfile test_overlap_qc --freq --noweb")
    system("mv plink.frq test.frq")
    
    # If the disk size is highly limited, these files can be removed
    # system('rm test_overlap.*')
    # system('rm genepool_overlap*')
    # system('rm test_reich*')
    # system('rm reich_here*')
    # system('rm CONVERTTest.map')
    # system('rm CONVERTTest.log')
    # system('rm CONVERTTest.nosex')
    
    ########## Generate minor allele frequency table for test dataset ##########
    ##### Construct MAF table #####
    # extracted markers from reference
    marker_frq <- read.table('test.frq')
    marker_ped <- read.table('CONVERTTest.ped', sep = '\t')
    
    metasub_data <- maf_tbl_generation(marker_frq, marker_ped,
                                       'MAF_test.rdata')
    system('rm CONVERTTest.ped')
    
    
    ##### Add meta data to MAF table #####
    
    load('MAF_test.rdata')
    reference_fam <- read.table('test_sample', sep='\t')[-1,]
    metasub_data <- metasub_data[-which(metasub_data$Populations %in% c('NorthEastAsian', 'Mediterranean',
                                                                        'SouthAfrican', 'SouthWestAsian',
                                                                        'NativeAmerican', 'Oceanian',
                                                                        'SouthEastAsian', 'NorthernEuropean',
                                                                        'SubsaharanAfrican')), ]
    
    print(paste0('nrow of metasub_data after removing gene pools: ',nrow(metasub_data)))
    
    metasub_data$GRC <- NA
    for(i in 1:nrow(metasub_data)){
      metasub_data$GRC[i] <- as.character(reference_fam$V2[which(reference_fam$V1 == metasub_data$Populations[i])])
    }
    print('metasub_data:')
    str(metasub_data)
    
    # Add meta information
    meta <- read.csv('../meta_table')
    metasub_data_meta <- add_meta_reich(metasub_data, meta)
    
    if(sum(is.na(metasub_data_meta$longitude)) > 0){
      str(metasub_data_meta)
      stop(paste0('Number of NA longitude: ',sum(is.na(metasub_data_meta$longitude))))
    }else{
      metasub_data_meta$latitude <- as.numeric(metasub_data_meta$latitude)
      metasub_data_meta$longitude <- as.numeric(metasub_data_meta$longitude)
      
      print('metasub_data_meta:')
      str(metasub_data_meta)
      
      save(metasub_data_meta, file='metasub_data_maf_test.rdata')
      system('rm MAF_test.rdata')
    }
    
    
    ########## feature selection with null importance for test set ##########
    
    ##### Data preparation #####
    load('metasub_data_maf_test.rdata')
    
    trial_dt <- metasub_data_meta
    trial_dt <- trial_dt[,c(2:(ncol(trial_dt)-4),
                            grep('latitude', colnames(trial_dt)),
                            grep('longitude', colnames(trial_dt)))] # only remains MAF columns, latitude column, and longitude column 
    
    x <- trial_dt
    features <- colnames(trial_dt)[c(1:(ncol(trial_dt)-2))]
    if(length(features) + 5 != ncol(metasub_data_meta)){ # 5 columns : Populations, GRC, country, latitude, longitude
      stop('Number of length +5 not equal to MAF table') # if the equation does not meet, more/less features were extracted
    }
    
    
    ##### benchmarking generation #####
    benchmark <- null_importance_select(x=x, features= features,
                                        shuffle=F, seed=123)
    print('benchmark:')
    head(benchmark)
    
    save(benchmark, file = 'benchmark_test.rdata')
    write.table(benchmark$feature, file = 'benchmark_test.snp', quote = F, row.names = F, col.names = F)
    
    ##### null importance #####
    null_imp_df <- data.frame()
    nb_runs <- 80 # shuffle 80 times
    start_time <- Sys.time()
    dsp <- c() 
    for(i in 1:nb_runs){
      # Get current run importances
      imp_df <- null_importance_select(x=x, features= features,
                                       shuffle=T, seed=123)
      imp_df$run <- i
      # Concat the latest importances with the old ones
      if(nrow(null_imp_df)==0){
        null_imp_df <- imp_df
      }else{
        null_imp_df<- rbind(null_imp_df, imp_df)
      }
      # Display current run and time used
      spent = Sys.time() - start_time
      dsp <- c(dsp,paste0('Done with    ', i,' of ',nb_runs, '    (spent ', spent,')' )) 
      print(dsp)
      
    }
    end_time <- Sys.time()
    time_for_testPreds_ind <- end_time - start_time
    print(time_for_testPreds_ind)
    
    print('null_imp_df:')
    head(null_imp_df)
    
    save(null_imp_df, file = 'null_imp_df_test.rdata')
    
    
    ##### sync features in null importance and benchmark #####
    load('null_imp_df_test.rdata')
    load('benchmark_test.rdata')
    null_imp_df.cp <- null_imp_df
    benchmark.cp <- benchmark
    null_imp_fea <- unique(null_imp_df.cp$feature)
    
    # if features in benchmark does not present in features in data frame having 80 shuffle feature importance results, add this benchmark feature.
    for(j in 1:nrow(benchmark.cp)){ 
      current_fea_benchmark <- benchmark.cp$feature[j]
      if(!current_fea_benchmark %in% null_imp_df$feature){
        null_imp_df <- rbind(as.data.frame(null_imp_df),
                             c(current_fea_benchmark, 0, 0, 0))
      }
    }
    if(sum(!benchmark.cp$feature %in% null_imp_fea) + length(null_imp_fea) != length(unique(null_imp_df$feature))){
      print(paste0('num of features in benchmark not in null_imp + num of features in null_imp: ',sum(!benchmark.cp$feature %in% null_imp_fea) + length(null_imp_fea)))
      print(paste0('num of features in null_imp after adding', length(unique(null_imp_df$feature))))
      stop('check the equivalence between benchmark$feature and null_imp$feature')
      
    }else{
      # if features in data frame having 80 shuffle feature importance results does not present in features in benchmark, add this feature
      for(i in 1:length(null_imp_fea)){
        current_fea <- null_imp_fea[i]
        if(!current_fea %in% benchmark$feature){
          benchmark <- rbind(as.data.frame(benchmark), c(current_fea, 0, 0))
        }
      }
      
      if(  nrow(benchmark) == length(unique(null_imp_df$feature)) ){
        benchmark$importance_gain <- as.numeric(benchmark$importance_gain)
        benchmark$importance_split <- as.numeric(benchmark$importance_split)
        null_imp_df$importance_gain <- as.numeric(null_imp_df$importance_gain)
        null_imp_df$importance_split <- as.numeric(null_imp_df$importance_split)
        null_imp_df$run <- as.numeric(null_imp_df$run)
        
        save(benchmark, file = 'benchmark_full_test.rdata')
        save(null_imp_df, file = 'null_imp_df_full_test.rdata')
        
      }else{
        print('num of features in benchmark: ', nrow(benchmark))
        print('num of features in null_imp: ', length(unique(null_imp_df$feature)))
        stop('num of row in benchmark does not equal to features in null_imp_df')
      }
      
    }
    
    
    
    ##### calculate the feature scoring for each feature in benchmark #####
    load('benchmark_full_test.rdata')
    load('null_imp_df_full_test.rdata')
    
    feature_scores <- data.frame(feature=NA, split_score=NA, gain_score=NA)
    for (f in unique(benchmark$feature)){
      f_null_imps_gain <- null_imp_df$importance_gain[null_imp_df$feature == f]
      f_act_imps_gain <- mean(benchmark$importance_gain[benchmark$feature == f])
      gain_score <- log(1e-10 + f_act_imps_gain / (1 + quantile(f_null_imps_gain, c(.75))[[1]]))  # Avoid divide by zero
      f_null_imps_split <- null_imp_df$importance_split[null_imp_df$feature == f]
      f_act_imps_split <- mean(benchmark$importance_split[benchmark$feature == f])
      split_score <- log(1e-10 + f_act_imps_split / (1 +  quantile(f_null_imps_split, c(.75))[[1]]))  # Avoid divide by zero
      feature_scores<- rbind(feature_scores,
                             c(f, split_score, gain_score))
      
    }
    
    scores_df <- feature_scores[-1,]
    scores_df$split_score <- as.numeric(scores_df$split_score)
    scores_df$gain_score <- as.numeric(scores_df$gain_score)
    
    print('75 percentile scores_df:')
    str(scores_df)
    
    save(scores_df, file = 'scores_df_75_test.rdata')
    
    #### select the features in top 300 feature score ####
    filter_selected_fea <- scores_df$feature[which(scores_df$gain_score>0 & scores_df$split_score>0)]
    
    filter_selected_fea.order <- filter_selected_fea[order(filter_selected_fea, decreasing = T),]
    write.table(filter_selected_fea.order[c(1:300)], file = 'split300_test.snp', quote = F, row.names = F, col.names = F)
    
    
    
    
    
    ########## Extract selected SNPs in training set + Run ADMIXTURE in supervised mode for training set after feature selection  ##########
    
    # extract selected SNPs from the training set
    load('metasub_data_maf_test.rdata')
    
    system("plink --bfile test_overlap_qc --extract split300_test.snp --make-bed --out selected_fea_score_test")
  ```                                
                                 
* 2.6. Confirm the performance of curated AIM set using AADR set 
  
  3 AIM sets for training set and test set will be tested:
                                 
  1. baseline
        
  2. AIMs found in the benchamrk of feature selection with null importance (benchmark)
                                 
  3. AIMs in top 300 feature scores from feature selection with null importance (split300)
                                 
  ```console
     # since the coding of base is different for AADR set and ancestral population set, convert the base in AADR set
      ~/bin/plink-1.07-x86_64/plink --bfile ../reich_here_overlap --allele1234 --make-bed --out reich_here_overlap_qc --noweb

      # try to merge training set with ancestral population set, will get an error due to different allelic location in 2 sets, will automatically generate a .missnp file
      plink --bfile reich_here_overlap_qc --bmerge ../genepool_overlap.bed ../../genepool_overlap.bim ../../genepool_overlap.fam  --make-bed --out baseline_overlap --noweb --allow-no-sex

      # remove SNPs in different alleleic location
      plink --bfile ../../genepool_overlap --exclude genepool_overlap_missnp --make-bed --out genepool_overlap_qc
      plink --bfile reference_reich_qc --exclude reference_reich_qc_missnp --make-bed --out reich_here_qc2                            
  ```
                                 
    + Use test set samples and selected AIMs to train and predict the training set 
                                 
    Create corresponding directory for the following the test, and naviagte into the directory
    ```r
       setwd('~/')
       system('mkdir test_train')
       setwd(paste0('~/dt',<best_num>,'/test_train')) # <best_num> = the_best_set[,1]     
       system('sh test_train')
    ```
    where *test_train*:  
    (Prepare training set and test set + run ADMIXTURE in supervised mode for all AIM sets)
    ```console
      ## use test set to model training set

      # extract samples from test set in best split set as samples in this training set
      plink --bfile ../reich_here_overlap_qc2 --keep ../test_sample --make-bed --out test_training

      # Since there was no samples having all SNPs missing (i.e no sample removed in quality control step), the quality control step is skipped here
      plink --bfile test_training --bmerge ../genepool_overlap_qc.bed ../genepool_overlap_qc.bim ../genepool_overlap_qc.fam  --make-bed --out test_training_baseline_overlap --allow-no-sex

      # run ADMIXTURE for this training set with all AIMs as baseline
      cut -f1-2 -d ' ' test_training_baseline_overlap.fam > test_training_baseline_overlap.pop.txt

      printf '%.0s\n' {1..1621} > test_training_baseline_overlap.pop

      cat test_training_baseline_overlap.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_training_baseline_overlap.pop

      ~/admixture32 test_training_baseline_overlap.bed -F 9 -j8
      cat test_training_baseline_overlap.fam | cut -d ' ' -f1-2 > test_training_out_ind_id
      sed -i 's/ /\t/g' test_training_out_ind_id
      sed -i 's/ /\t/g' test_training_baseline_overlap.9.Q
      paste test_training_out_ind_id test_training_baseline_overlap.9.Q > out_Q_test_training_baseline
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_training_baseline

      # extract AIMs selected from the benchmark in feature selection with null importance, and run ADMIXTURE for this training set with these AIMs
      plink --bfile test_training_baseline_overlap --extract ../benchmark_test.snp  --make-bed --out test_training_selected_bench --noweb

      cut -f1-2 -d ' ' test_training_selected_bench.fam > test_training_selected_bench.pop.txt
      printf '%.0s\n' {1..1621}  > test_training_selected_bench.pop
      wc -l test_training_selected_bench.pop

      cat test_training_selected_bench.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_training_selected_bench.pop
      wc -l test_training_selected_bench.pop

      ~/admixture32 test_training_selected_bench.bed -F 9 -j8
      cat test_training_selected_bench.fam | cut -d ' ' -f1-2 > test_training_out_ind_id_bench
      sed -i 's/ /\t/g' test_training_out_ind_id_bench
      sed -i 's/ /\t/g' test_training_selected_bench.9.Q
      paste test_training_out_ind_id_bench test_training_selected_bench.9.Q > out_Q_test_training_bench
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_training_bench

      # extract AIMs selected from top300 feature scores in feature selection with null importance, and run ADMIXTURE for this training set with these AIMs

      plink --bfile test_training_baseline_overlap --extract ../split300_test.snp  --make-bed --out test_training_selected_split300 --noweb

      cut -f1-2 -d ' ' test_training_selected_split300.fam > test_training_selected_split300.pop.txt
      printf '%.0s\n' {1..1621}  > test_training_selected_split300.pop

      cat test_training_selected_split300.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_training_selected_split300.pop

      ~/admixture32 test_training_selected_split300.bed -F 9 -j8
      cat test_training_selected_split300.fam | cut -d ' ' -f1-2 > test_training_out_ind_id_split300
      sed -i 's/ /\t/g' test_training_out_ind_id_split300
      sed -i 's/ /\t/g' test_training_selected_split300.9.Q
      paste test_training_out_ind_id_split300 test_training_selected_split300.9.Q > out_Q_test_training_split300
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_training_split300






      # extract samples from training set in best split set as samples in this test set
      plink --bfile ../reich_here_overlap_qc2 --keep ../reference_sample --make-bed --out test_test

      plink --bfile test_test --bmerge ../genepool_overlap_qc.bed ../genepool_overlap_qc.bim ../genepool_overlap_qc.fam  --make-bed --out test_test_baseline_overlap --allow-no-sex

      # run ADMIXTURE for this test set with all AIMs as baseline
      cut -f1-2 -d ' ' test_test_baseline_overlap.fam > test_test_baseline_overlap.pop.txt

      printf '%.0s\n' {1..1756} > test_test_baseline_overlap.pop

      cat test_test_baseline_overlap.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_test_baseline_overlap.pop

      ~/admixture32 test_test_baseline_overlap.bed -F 9 -j8
      cat test_test_baseline_overlap.fam | cut -d ' ' -f1-2 > test_test_out_ind_id
      sed -i 's/ /\t/g' test_test_out_ind_id
      sed -i 's/ /\t/g' test_test_baseline_overlap.9.Q
      paste test_test_out_ind_id test_test_baseline_overlap.9.Q > out_Q_test_test_baseline
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_test_baseline


      # extract AIMs selected from the benchmark in feature selection with null importance, and run ADMIXTURE for this test set with these AIMs
      plink --bfile test_test_baseline_overlap --extract ../benchmark_test.snp  --make-bed --out test_test_selected_bench --noweb

      cut -f1-2 -d ' ' test_test_selected_bench.fam > test_test_selected_bench.pop.txt
      printf '%.0s\n' {1..1756}  > test_test_selected_bench.pop
      wc -l test_test_selected_bench.pop

      cat test_test_selected_bench.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_test_selected_bench.pop
      wc -l test_test_selected_bench.pop

      ~/admixture32 test_test_selected_bench.bed -F 9 -j8
      cat test_test_selected_bench.fam | cut -d ' ' -f1-2 > test_test_out_ind_id_bench
      sed -i 's/ /\t/g' test_test_out_ind_id_bench
      sed -i 's/ /\t/g' test_test_selected_bench.9.Q
      paste test_test_out_ind_id_bench test_test_selected_bench.9.Q > out_Q_test_test_bench
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_test_bench

      # extract AIMs selected from top300 feature scores in feature selection with null importance, and run ADMIXTURE for this test set with these AIMs

      plink --bfile test_test_baseline_overlap --extract ../split300_test.snp  --make-bed --out test_test_selected_split300 --noweb

      cut -f1-2 -d ' ' test_test_selected_split300.fam > test_test_selected_split300.pop.txt
      printf '%.0s\n' {1..1756}  > test_test_selected_split300.pop

      cat test_test_selected_split300.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_test_selected_split300.pop

      ~/admixture32 test_test_selected_split300.bed -F 9 -j8
      cat test_test_selected_split300.fam | cut -d ' ' -f1-2 > test_test_out_ind_id_split300
      sed -i 's/ /\t/g' test_test_out_ind_id_split300
      sed -i 's/ /\t/g' test_test_selected_split300.9.Q
      paste test_test_out_ind_id_split300 test_test_selected_split300.9.Q > out_Q_test_test_split300
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_test_split300


      Rscript --vanilla ../run_rf_train_test.R test

    ```
  
    where *run_rf_train_test.R*:
    ```r
    args <- commandArgs(trailingOnly=TRUE)
    iteration <- c('baseline', 'bench', 'split300')
    ind <- args[[1]]
    
    for(ite in iteration){ # baseline; benchmark; split300
    
      qfile_train <- read.table(paste0('out_Q_',ind,'_training_',ite), header = T, sep = '\t') 
      qfile_test <- read.table(paste0('out_Q_',ind,'_test_',ite), header = T, sep = '\t')
      
      # Add meta information for training set
      meta <- read.csv('meta_table') #nrow(meta)=14008
    
      qfile_train_nogp <- qfile_train[-which(qfile_train$Population %in% c('NorthEastAsian', 'Mediterranean',
                                                                           'SouthAfrican', 'SouthWestAsian',
                                                                           'NativeAmerican', 'Oceanian',
                                                                           'SouthEastAsian', 'NorthernEuropean',
                                                                           'SubsaharanAfrican')), ]
      qfile_train_nogp$Populations<- as.character(qfile_train_nogp$Populations)
      qfile_train_nogp_popFilter <- add_meta_reich(qfile_train_nogp, meta)
      qfile_train_nogp_popFilter <- droplevels(qfile_train_nogp_popFilter)
      print('qfile_train_nogp_popFilter:')
      str(qfile_train_nogp_popFilter)
      
      # Add meta information for test set
      qfile_test_nogp <- qfile_test[-which(qfile_test$Population %in% c('NorthEastAsian', 'Mediterranean',
                                                                        'SouthAfrican', 'SouthWestAsian',
                                                                        'NativeAmerican', 'Oceanian',
                                                                        'SouthEastAsian', 'NorthernEuropean',
                                                                        'SubsaharanAfrican')), ]
      qfile_test_nogp$Populations<- as.character(qfile_test_nogp$Populations)
      qfile_test_nogp_popFilter <- add_meta_reich(qfile_test_nogp, meta)
      qfile_test_nogp_popFilter <- droplevels(qfile_test_nogp_popFilter)
      print('qfile_test_nogp_popFilter:')
      str(qfile_test_nogp_popFilter)
      
      qfile_train_nogp_popFilter$GRC <- as.character(qfile_train_nogp_popFilter$GRC)
      qfile_test_nogp_popFilter$GRC <- as.character(qfile_test_nogp_popFilter$GRC)
      
      # In case any invalid longitude value in meta data leads to error in model training, remove corresponding samples
      if(sum(is.na(qfile_train_nogp_popFilter$longitude)) > 0){
        qfile_train_nogp_popFilter <- qfile_train_nogp_popFilter[-which(is.na(qfile_train_nogp_popFilter$longitude)),]
      }
      if(sum(is.na(qfile_test_nogp_popFilter$longitude)) > 0){
        qfile_test_nogp_popFilter <- qfile_test_nogp_popFilter[-which(is.na(qfile_test_nogp_popFilter$longitude)),]
      }
      
      # Model training and prediction
      rf_model_training_train_test(qfile_train_nogp_popFilter, qfile_test_nogp_popFilter, tag = c(ind, ite))
      
    }

    ```
    + Use training set samples and selected AIMs to train and predict test set 
                                 
    Create corresponding directory for the following the test, and naviagte into the directory
    ```r
       system('mkdir ../train_test')
       setwd(paste0('~/dt', <best_num> ,'/train_test')) # <best_num> = the_best_set[,1]     
       system('sh train_test')
    ```
    where *train_test*:  
    (Prepare training set and test set + run ADMIXTURE in supervised mode for all AIM sets)
    ```console  
       ## use training set to model test set 

      # extract samples from test set in best split set as samples in this training set
      plink --bfile ../reich_here_overlap_qc2 --keep ../reference_sample --make-bed --out test_training

      # Since there was no samples having all SNPs missing (i.e no sample removed in quality control step), the quality control step is skipped here
      plink --bfile test_training --bmerge ../genepool_overlap_qc.bed ../genepool_overlap_qc.bim ../genepool_overlap_qc.fam  --make-bed --out test_training_baseline_overlap --allow-no-sex

      cut -f1-2 -d ' ' test_training_baseline_overlap.fam > test_training_baseline_overlap.pop.txt

      printf '%.0s\n' {1..1756} > test_training_baseline_overlap.pop

      cat test_training_baseline_overlap.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_training_baseline_overlap.pop

      ~/admixture32 test_training_baseline_overlap.bed -F 9 -j8
      cat test_training_baseline_overlap.fam | cut -d ' ' -f1-2 > test_training_out_ind_id
      sed -i 's/ /\t/g' test_training_out_ind_id
      sed -i 's/ /\t/g' test_training_baseline_overlap.9.Q
      paste test_training_out_ind_id test_training_baseline_overlap.9.Q > out_Q_test_training_baseline
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_training_baseline

      # extract AIMs selected from the benchmark in feature selection with null importance, and run ADMIXTURE for this training set with these AIMs
      plink --bfile test_training_baseline_overlap --extract ../benchmark.snp  --make-bed --out test_training_selected_bench --noweb

      cut -f1-2 -d ' ' test_training_selected_bench.fam > test_training_selected_bench.pop.txt
      printf '%.0s\n' {1..1756}  > test_training_selected_bench.pop
      wc -l test_training_selected_bench.pop

      cat test_training_selected_bench.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_training_selected_bench.pop
      wc -l test_training_selected_bench.pop

      ~/admixture32 test_training_selected_bench.bed -F 9 -j8
      cat test_training_selected_bench.fam | cut -d ' ' -f1-2 > test_training_out_ind_id_bench
      sed -i 's/ /\t/g' test_training_out_ind_id_bench
      sed -i 's/ /\t/g' test_training_selected_bench.9.Q
      paste test_training_out_ind_id_bench test_training_selected_bench.9.Q > out_Q_test_training_bench
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_training_bench

      # extract AIMs selected from top300 feature scores in feature selection with null importance, and run ADMIXTURE for this training set with these AIMs

      plink --bfile test_training_baseline_overlap --extract ../split300.snp  --make-bed --out test_training_selected_split300 --noweb

      cut -f1-2 -d ' ' test_training_selected_split300.fam > test_training_selected_split300.pop.txt
      printf '%.0s\n' {1..1756}  > test_training_selected_split300.pop

      cat test_training_selected_split300.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_training_selected_split300.pop

      ~/admixture32 test_training_selected_split300.bed -F 9 -j8
      cat test_training_selected_split300.fam | cut -d ' ' -f1-2 > test_training_out_ind_id_split300
      sed -i 's/ /\t/g' test_training_out_ind_id_split300
      sed -i 's/ /\t/g' test_training_selected_split300.9.Q
      paste test_training_out_ind_id_split300 test_training_selected_split300.9.Q > out_Q_test_training_split300
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_training_split300






      # extract samples from training set in best split set as samples in this test set
      plink --bfile ../reich_here_overlap_qc2 --keep sample_feature/test_sample --make-bed --out test_test

      plink --bfile test_test --bmerge ../genepool_overlap_qc.bed ../genepool_overlap_qc.bim ../genepool_overlap_qc.fam  --make-bed --out test_test_baseline_overlap --allow-no-sex

      # run ADMIXTURE for this test set with all AIMs as baseline
      cut -f1-2 -d ' ' test_test_baseline_overlap.fam > test_test_baseline_overlap.pop.txt

      printf '%.0s\n' {1..1621} > test_test_baseline_overlap.pop

      cat test_test_baseline_overlap.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_test_baseline_overlap.pop

      ~/admixture32 test_test_baseline_overlap.bed -F 9 -j8
      cat test_test_baseline_overlap.fam | cut -d ' ' -f1-2 > test_test_out_ind_id
      sed -i 's/ /\t/g' test_test_out_ind_id
      sed -i 's/ /\t/g' test_test_baseline_overlap.9.Q
      paste test_test_out_ind_id test_test_baseline_overlap.9.Q > out_Q_test_test_baseline
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_test_baseline

      # extract AIMs selected from the benchmark in feature selection with null importance, and run ADMIXTURE for this test set with these AIMs
      plink --bfile test_test_baseline_overlap --extract ../benchmark.snp  --make-bed --out test_test_selected_bench --noweb

      cut -f1-2 -d ' ' test_test_selected_bench.fam > test_test_selected_bench.pop.txt
      printf '%.0s\n' {1..1621}  > test_test_selected_bench.pop
      wc -l test_test_selected_bench.pop

      cat test_test_selected_bench.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_test_selected_bench.pop
      wc -l test_test_selected_bench.pop

      ~/admixture32 test_test_selected_bench.bed -F 9 -j8
      cat test_test_selected_bench.fam | cut -d ' ' -f1-2 > test_test_out_ind_id_bench
      sed -i 's/ /\t/g' test_test_out_ind_id_bench
      sed -i 's/ /\t/g' test_test_selected_bench.9.Q
      paste test_test_out_ind_id_bench test_test_selected_bench.9.Q > out_Q_test_test_bench
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_test_bench

      # extract AIMs selected from top300 feature scores in feature selection with null importance, and run ADMIXTURE for this test set with these AIMs

      plink --bfile test_test_baseline_overlap --extract ../split300.snp  --make-bed --out test_test_selected_split300 --noweb

      cut -f1-2 -d ' ' test_test_selected_split300.fam > test_test_selected_split300.pop.txt
      printf '%.0s\n' {1..1621}  > test_test_selected_split300.pop

      cat test_test_selected_split300.pop.txt | grep -E 'NorthEastAsian|Mediterranean|SouthAfrican|SouthWestAsian|NativeAmerican|Oceanian|SouthEastAsian|NorthernEuropean|SubsaharanAfrican' | cut -f1 -d' ' >> test_test_selected_split300.pop

      ~/admixture32 test_test_selected_split300.bed -F 9 -j8
      cat test_test_selected_split300.fam | cut -d ' ' -f1-2 > test_test_out_ind_id_split300
      sed -i 's/ /\t/g' test_test_out_ind_id_split300
      sed -i 's/ /\t/g' test_test_selected_split300.9.Q
      paste test_test_out_ind_id_split300 test_test_selected_split300.9.Q > out_Q_test_test_split300
      sed -i '1 i\Populations\tGRC\tMediterranean\tNative American\tNortheast Asian\tNorthern European\tOceanian\tSouthern African\tSoutheast Asian\tSouthwest Asian\tSubsaharan African'  out_Q_test_test_split300


      Rscript --vanilla ../run_rf_train_test.R test
    ```
    
    where run_rf_train_test.R is same to the one in *using test set to predict training set*
  
  
      
  
                                 
                           
 
  
                


